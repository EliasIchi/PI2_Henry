{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44760f5b-965b-4a36-8058-6922be50d6f2",
   "metadata": {},
   "source": [
    "# <center>PROYECTO INDIVIDUAL SINIESTROS VIALES (CABA)<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6789019-617a-437d-83ba-d1d4feb3bc72",
   "metadata": {},
   "source": [
    "## <center>ETL (Extract, Transform, Load)<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad7585a-d872-4749-9b4b-c61c1ff4eb53",
   "metadata": {},
   "source": [
    "### A continuación nos conectaremos con Python, a través de jupyter notebooks para preparar los datos de tal manera que se puedan cargar en un database online: se pasaran los archivos a .csv para imputar facilmente luego en script.sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11165e8e-bd8f-4b98-992b-c7e103e47926",
   "metadata": {},
   "source": [
    "### dataset homicidios, se adaptan de tal manera que sea compatible con mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504818dd-1ae5-4288-86b9-79165e2bfbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# URLs de los libros de Excel\n",
    "url_homicidios = \"https://cdn.buenosaires.gob.ar/datosabiertos/datasets/transporte-y-obras-publicas/victimas-siniestros-viales/homicidios.xlsx\"\n",
    "url_lesiones = \"https://cdn.buenosaires.gob.ar/datosabiertos/datasets/transporte-y-obras-publicas/victimas-siniestros-viales/lesiones.xlsx\"\n",
    "\n",
    "# Leer los libros de Excel y obtener información sobre las hojas\n",
    "xls_homicidios = pd.ExcelFile(url_homicidios)\n",
    "xls_lesiones = pd.ExcelFile(url_lesiones)\n",
    "\n",
    "# Obtener nombres de las hojas y cantidad de hojas\n",
    "nombres_hojas_homicidios = xls_homicidios.sheet_names\n",
    "nombres_hojas_lesiones = xls_lesiones.sheet_names\n",
    "cantidad_hojas_homicidios = len(nombres_hojas_homicidios)\n",
    "cantidad_hojas_lesiones = len(nombres_hojas_lesiones)\n",
    "df_homicidios_primera_hoja = pd.read_excel(url_homicidios, sheet_name=nombres_hojas_homicidios[0])\n",
    "h_victimas = df_homicidios_primera_hoja = pd.read_excel(url_homicidios, sheet_name=nombres_hojas_homicidios[2])\n",
    "h_hechos = df_homicidios_primera_hoja = pd.read_excel(url_homicidios, sheet_name=nombres_hojas_homicidios[0])\n",
    "\n",
    "# Lista de columnas en las que se agregarán comillas simples\n",
    "columnas_con_comillas = ['ID', 'FECHA', 'HORA', 'LUGAR_DEL_HECHO', 'TIPO_DE_CALLE', \n",
    "                         'Calle', 'Cruce', 'Dirección Normalizada', 'XY (CABA)', \n",
    "                         'PARTICIPANTES', 'VICTIMA', 'ACUSADO']\n",
    "\n",
    "h_hechos['HH'].replace('SD', 'null', inplace=True)\n",
    "# Agregar comillas simples a todas las celdas de las columnas especificadas\n",
    "for columna in columnas_con_comillas:\n",
    "    h_hechos[columna] = h_hechos[columna].apply(lambda x: f\"'{x}'\")\n",
    "\n",
    "# Convertir celdas vacías o que contengan solo espacios en blanco a NaN\n",
    "h_hechos = h_hechos.replace({'': np.nan, \"''\": np.nan})\n",
    "# Reemplazar valores en la columna \"pos x\" donde aparece \".\"\n",
    "h_hechos.loc[h_hechos['Altura'] == '', 'Altura'] = 'null'\n",
    "# Reemplazar valores NaN en la columna \"Altura\" por \"null\"\n",
    "h_hechos['Altura'].fillna('null', inplace=True)\n",
    "\n",
    "h_hechos.loc[h_hechos['Altura'] == '.', 'Altura'] = 'null'\n",
    "h_hechos.loc[h_hechos['pos x'] == '.', 'pos x'] = 'null'\n",
    "h_hechos.loc[h_hechos['pos y'] == '.', 'pos y'] = 'null'\n",
    "import pandas as pd\n",
    "\n",
    "# Crear una lista para almacenar las filas concatenadas\n",
    "filas_concatenadas = []\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame\n",
    "for indice, fila in h_hechos.iterrows():\n",
    "    # Concatenar los valores de la fila separados por comas\n",
    "    fila_concatenada = \"(\" + \", \".join(map(str, fila.values)) + \")\"\n",
    "    # Agregar la fila concatenada a la lista\n",
    "    filas_concatenadas.append(fila_concatenada)\n",
    "\n",
    "# Reemplazar la coma final por un punto y coma en la última fila\n",
    "filas_concatenadas[-1] = filas_concatenadas[-1].replace(\",\", \";\")\n",
    "\n",
    "# Crear un DataFrame con una sola columna y asignar las filas concatenadas\n",
    "df_concatenado = pd.DataFrame(filas_concatenadas, columns=['Columna_Unica'])\n",
    "\n",
    "df_concatenado.to_csv(\"homicidios_sql.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e68a08-ffc6-4575-a3b5-afc79290adf8",
   "metadata": {},
   "source": [
    "### dataset victimas, se adaptan de tal manera que sea compatible con mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ccac7-0da4-4ed4-903f-9541c0bd9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo que h_victimas es tu DataFrame\n",
    "# Reemplazar \"SD\", \"Sd\" y \"sd\" por valores vacíos en todas las columnas del DataFrame\n",
    "for col in h_victimas.columns:\n",
    "    h_victimas[col] = h_victimas[col].replace([None], \"\")\n",
    "    columnas_con_comillas2 = ['ID_hecho', 'FECHA', 'ROL', 'VICTIMA', 'SEXO','FECHA_FALLECIMIENTO']\n",
    "\n",
    "# Agregar comillas simples a todas las celdas de las columnas especificadas\n",
    "for columna in columnas_con_comillas2:\n",
    "    h_victimas[columna] = h_victimas[columna].apply(lambda x: f\"'{x}'\")\n",
    "    h_victimas = h_victimas.drop(columns=[\"EDAD_GRUPO\"])\n",
    "h_victimas.to_csv(\"sql_victimas.csv\", index= False , encoding = \"utf-16\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981f89d-b713-4499-86d9-daedec377b26",
   "metadata": {},
   "source": [
    "### dataset poblacion por año, es un excel que tiene la poblacion por año pero en diferentes hojas, se extrajo de la pagina de estadisticas de buenos aires, se extraen todos los df en uno solo, de tal manera de crear una tabla con dato de poblacion por año y se adaptan de tal manera que sea compatible con mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b71053-d328-4790-8148-545bc911fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo Excel\n",
    "file_path = \"https://www.estadisticaciudad.gob.ar/eyc/wp-content/uploads/2021/05/PDE.xlsx\"\n",
    "\n",
    "# Leer el archivo Excel\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Crear un diccionario para almacenar los DataFrames de cada página\n",
    "dfs = {}\n",
    "\n",
    "# Iterar sobre cada página del archivo Excel\n",
    "for sheet_name in xls.sheet_names:\n",
    "    if sheet_name not in [\"Ficha Técnica\", \"PDE\"]:\n",
    "        # Leer la página del archivo Excel y omitir las primeras 1 filas\n",
    "        df = pd.read_excel(xls, sheet_name, header=None, skiprows=1)\n",
    "        # Extraer las filas requeridas (de la 4ta a la 19)\n",
    "        df = df.iloc[3:17]\n",
    "        # Agregar una columna con el nombre de la hoja\n",
    "        df['Hoja'] = sheet_name\n",
    "        # Almacenar el DataFrame en el diccionario utilizando el nombre de la página como clave\n",
    "        dfs[sheet_name] = df\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_concatenado = pd.concat(dfs.values(), ignore_index=True)\n",
    "\n",
    "# Renombrar las columnas\n",
    "df_concatenado.columns = [\"comuna\", \"total\", \"masculino\", \"femenino\", \"superficie_km2\", \"densidad_poblacion_hab_km2\", \"anio\"]\n",
    "\n",
    "poblacion = df_concatenado \n",
    "poblacion.to_csv(\"poblacion.csv\", index = False)\n",
    "poblacion.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310943f-6e3a-4a96-a761-04c85bd6508c",
   "metadata": {},
   "source": [
    "### extracción de dataset comuna, nos trae datos precisos con ID, se suman para realizar al dashboard, no necesitan transformación, se manejara en excel de tal manera que sea compatible para cargar en el database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560cfb97-620d-4510-8053-79d11e80f617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed96860-d38a-42d1-b04a-a89c94c539d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>OBJETO</th>\n",
       "      <th>COMUNAS</th>\n",
       "      <th>BARRIOS</th>\n",
       "      <th>PERIMETRO</th>\n",
       "      <th>AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LIMITE COMUNAL</td>\n",
       "      <td>2</td>\n",
       "      <td>RECOLETA</td>\n",
       "      <td>21452.838648</td>\n",
       "      <td>6.317265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LIMITE COMUNAL</td>\n",
       "      <td>5</td>\n",
       "      <td>ALMAGRO - BOEDO</td>\n",
       "      <td>12323.432479</td>\n",
       "      <td>6.660603e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>LIMITE COMUNAL</td>\n",
       "      <td>6</td>\n",
       "      <td>CABALLITO</td>\n",
       "      <td>10990.964471</td>\n",
       "      <td>6.851029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LIMITE COMUNAL</td>\n",
       "      <td>7</td>\n",
       "      <td>FLORES - PARQUE CHACABUCO</td>\n",
       "      <td>17972.257870</td>\n",
       "      <td>1.242290e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>LIMITE COMUNAL</td>\n",
       "      <td>9</td>\n",
       "      <td>LINIERS - MATADEROS - PARQUE AVELLANEDA</td>\n",
       "      <td>21411.738344</td>\n",
       "      <td>1.650531e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          OBJETO  COMUNAS                                  BARRIOS  \\\n",
       "0   1  LIMITE COMUNAL        2                                 RECOLETA   \n",
       "1   2  LIMITE COMUNAL        5                          ALMAGRO - BOEDO   \n",
       "2   3  LIMITE COMUNAL        6                                CABALLITO   \n",
       "3   4  LIMITE COMUNAL        7                FLORES - PARQUE CHACABUCO   \n",
       "4   5  LIMITE COMUNAL        9  LINIERS - MATADEROS - PARQUE AVELLANEDA   \n",
       "\n",
       "      PERIMETRO          AREA  \n",
       "0  21452.838648  6.317265e+06  \n",
       "1  12323.432479  6.660603e+06  \n",
       "2  10990.964471  6.851029e+06  \n",
       "3  17972.257870  1.242290e+07  \n",
       "4  21411.738344  1.650531e+07  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL del archivo Excel\n",
    "url = \"https://cdn.buenosaires.gob.ar/datosabiertos/datasets/ministerio-de-educacion/comunas/comunas.xlsx\"\n",
    "\n",
    "# Leer el archivo Excel y convertirlo en un DataFrame\n",
    "comuna = pd.read_excel(url)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para verificar la carga de datos\n",
    "comuna.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
